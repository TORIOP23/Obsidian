- Representing words as points in a hight-dimensional space, rather than as atomic value
3 approach
- **One-hot encoding**
- **Count-based representation**
- **SLIM combination**

## Frequency-based embedding
- Count Vector
- tf-idf Vector
	- **TF-IDF** (Term Frequency - Inverse Document Frequency)
- Co-occurrence Matrix
	- **GloVe** (Global Vectors)
## Prediction-based embedding. (neutral)
- **Word2vec**: two-layer neural network-based algorithm
- **fasText**
- **ELMo** (Embeddings from Language Models)
## Reduce dimension
- [[SVD]]
- PCA
- Auto encoder
- [[word2vec]]