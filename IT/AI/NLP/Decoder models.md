- At each stage, for a given word the attention layers can only access the words positioned before it in the sentence 
- These models are often calledÂ _auto-regressive models_.
- Tasks: Text generation
- Train: predict the next word in a sequence
Example
- CTRL
- GPT
- GPT-2
- Transformer XL