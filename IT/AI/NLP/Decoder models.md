- At each stage, for a given word the attention layers can only access the words positioned before it in the sentence 
- These models are often calledÂ _auto-regressive models_.
- Tasks: Text generation
Example
- CTRL
- GPT
- GPT-2
- Transformer XL