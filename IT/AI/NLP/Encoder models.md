- At each stage, the attention layers can access all the words in the initial sentence.
- These models are often characterized as having “bi-directional” attention, and are often called _auto-encoding models_.
- Tasks: Sentence classification, named entity recognition, extractive question answering
Example
- ALBERT
- BERT
- DistilBERT
- ELECTRA
- RoBERTa