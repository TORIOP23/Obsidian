- Encoder và decoder
- At each stage, the attention layers of the encoder can access all the words in the initial sentence, whereas the attention layers of the decoder can only access the words positioned before a given word in the input.
- Nhận input là một sequence và trả lại output cũng là một sequence.
- Tasks: summarization, translation, or generative question answering.
Example
- BART
- mBART
- Marian
- T5